{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import layers\n",
    "from keras.utils import np_utils\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix,\n",
    "    accuracy_score\n",
    ")\n",
    "from sklearn.model_selection import (\n",
    "    train_test_split as tts,\n",
    "    StratifiedKFold)\n",
    "from sklearn.utils.multiclass import type_of_target\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_kmers(sequences, kmer=4):\n",
    "    return_seqs = sequences.copy()\n",
    "    if kmer <= 1:\n",
    "        raise ValueError(\"kmer size must be greater than 1\")\n",
    "    for seq_index, seq in sequences.iteritems():\n",
    "        kmer_list = []\n",
    "        for let_index, let in enumerate(seq[:-kmer + 1]):\n",
    "            kmer_list.append(seq[let_index:let_index + kmer])\n",
    "        return_seqs[seq_index] = kmer_list\n",
    "    return return_seqs\n",
    "\n",
    "def get_2d_kmer(seqs, mnm, mxm):\n",
    "    return_seqs = []\n",
    "    for _, val in seqs.iteritems():\n",
    "        kmer_seqs = []\n",
    "        for i in range(mnm, mxm+1):\n",
    "            kmers = list(get_kmers(pd.Series([val]), kmer=i))[0]\n",
    "            # kmers += [kmers[-1] for _ in range(i-1)]\n",
    "            kmer_seqs.append(kmers)\n",
    "        return_seqs.append(kmer_seqs)\n",
    "    \n",
    "    return pd.Series(return_seqs)\n",
    "\n",
    "def dup_vecs(dfs):\n",
    "    dup_X_2d = []\n",
    "    for df_ind, df in enumerate(dfs):\n",
    "        num_dupes = 4**(2-df_ind)\n",
    "        print(num_dupes)\n",
    "        new_df = df.values.tolist()\n",
    "        for ind, seq in enumerate(new_df):\n",
    "            new_seq = []\n",
    "            for num in seq:\n",
    "                for i in range(num_dupes):\n",
    "                    new_seq.append(num)\n",
    "            new_df[ind] = new_seq\n",
    "        dup_X_2d.append(pd.DataFrame(new_df))\n",
    "\n",
    "    return dup_X_2d\n",
    "\n",
    "def tfidf_vectorize(tfidf, series):\n",
    "    new_series = []\n",
    "    for ind, _ in enumerate(series[0]):\n",
    "        new_series.append([series[i][ind] for i, _ in series.iteritems()])\n",
    "\n",
    "    new_series = pd.Series(new_series)\n",
    "    # return new_series\n",
    "\n",
    "    new_dfs = []\n",
    "    for ind, val in new_series.iteritems():\n",
    "        new_dfs.append(pd.DataFrame(tfidf.fit_transform(\n",
    "            [' '.join(v) for _, v in pd.Series(val).iteritems()]\n",
    "        ).toarray()))\n",
    "    \n",
    "    return new_dfs\n",
    "\n",
    "def get_dup_X_2d(X):\n",
    "    X_2d = get_2d_kmer(X, 4, 6)\n",
    "    tfidf = TfidfVectorizer()\n",
    "    vectorized_2d = tfidf_vectorize(tfidf, X_2d)\n",
    "    dup_X_2d = dup_vecs(vectorized_2d)\n",
    "    dup_X_2d = [i.values.tolist() for i in dup_X_2d]\n",
    "    dup_X_2d = np.array([[dup_X_2d[i][ind] for i in range(len(dup_X_2d))] for ind in range(len(dup_X_2d[0]))])\n",
    "    dup_X_2d = dup_X_2d.reshape(*dup_X_2d.shape, 1).astype('float32')\n",
    "    return dup_X_2d\n",
    "\n",
    "def get_X_1d(X):\n",
    "    X_1d = get_kmers(X, kmer=3)\n",
    "    tfidf = TfidfVectorizer()\n",
    "    X_1d = pd.DataFrame(\n",
    "        tfidf.fit_transform(\n",
    "            [' '.join(val) for index, val in X_1d.iteritems()]\n",
    "        ).toarray())\n",
    "    print(X_1d.shape)\n",
    "    X_1d = np.asarray(X_1d).reshape(*(X_1d.shape), 1).astype('float32')\n",
    "\n",
    "\n",
    "opt = keras.optimizers.Adam(learning_rate=0.0005)\n",
    "\n",
    "def DCNNv2(num_features, num_classes):\n",
    "    model = keras.Sequential()\n",
    "    # model.add(layers.Dropout(0.1, input_shape=(num_features, 1)))\n",
    "    model.add(layers.Conv1D(100, 3, activation='softsign', strides=2, input_shape=(num_features, 1)))\n",
    "    model.add(layers.Conv1D(50, 3, activation='softsign', strides=2))\n",
    "    model.add(layers.Conv1D(32, 3, activation='softsign', strides=2))\n",
    "    model.add(layers.MaxPooling1D(2))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(32, activation='softsign'))\n",
    "    model.add(layers.Dropout(0.1))\n",
    "    # model.add(layers.Dropout(0.3))\n",
    "    model.add(layers.Dense(24, activation='softsign'))\n",
    "    model.add(layers.Dropout(0.2))\n",
    "    # model.add(layers.Dropout(0.3))\n",
    "    model.add(layers.Dense(16, activation='softsign'))\n",
    "    model.add(layers.Dropout(0.3))\n",
    "    # model.add(layers.Dropout(0.3))\n",
    "    model.add(layers.Dense(8, activation='softsign'))\n",
    "    model.add(layers.Dropout(0.4))\n",
    "    # model.add(layers.Dropout(0.3))\n",
    "    model.add(layers.Dense(num_classes, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "def DCNNv1(num_features, num_classes):\n",
    "    model = keras.Sequential()\n",
    "    model.add(layers.Dropout(0.1, input_shape=(num_features, 1)))\n",
    "    model.add(layers.Conv1D(32, 5, activation='softsign', input_shape=(num_features, 1)))\n",
    "    model.add(layers.Dropout(0.2))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.MaxPooling1D(2))\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(32, activation='softsign'))\n",
    "    model.add(layers.Dense(num_classes, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def DCNNv3(num_features, num_classes, num_kmers):\n",
    "    model = keras.Sequential()\n",
    "    model.add(layers.Dropout(0.1, input_shape=(num_kmers, num_features, 1)))\n",
    "    model.add(layers.Conv2D(32, (2, 3), activation='softsign', input_shape=(num_kmers, num_features, 1)))\n",
    "    model.add(layers.Dropout(0.1))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.MaxPooling2D(2))\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(32, activation='softsign'))\n",
    "    model.add(layers.Dense(num_classes, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def DCNNv4(num_features, num_classes, num_kmers):\n",
    "    inputs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../data/pro_nonpro.csv')\n",
    "data = data.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.Seq\n",
    "y = data.Level\n",
    "\n",
    "le = LabelEncoder()\n",
    "y = pd.Series(le.fit_transform(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# there are 4 letters, the vocabulary roughly follows powers of four because those are the possible combinations of length kmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorical_X_1d(X):\n",
    "    X_kmers = get_2d_kmer(X, mnm=3, mxm=6)\n",
    "    tfidf = TfidfVectorizer()\n",
    "    vectorized_2d = tfidf_vectorize(tfidf, X_kmers)\n",
    "    new_df = []\n",
    "    for seq_ind in range(len(vectorized_2d[0])):\n",
    "        new_row = []\n",
    "        for vec_ind in range(len(vectorized_2d)):\n",
    "            new_row += list(vectorized_2d[vec_ind].iloc[seq_ind,:])\n",
    "        \n",
    "        new_df.append(new_row)\n",
    "    \n",
    "    new_df = pd.DataFrame(new_df)\n",
    "\n",
    "    new_df = np.asarray(new_df).reshape(*new_df.shape, 1).astype('float32')\n",
    "    return new_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categ_X = categorical_X_1d(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = 5440\n",
    "num_classes = 2\n",
    "num_epochs = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_1d = np.asarray(X_1d).reshape(len(X_1d), num_features, 1).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kfold = StratifiedKFold(n_splits=5, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_2d = get_dup_X_2d(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = tts(categ_X, y, train_size=0.7)\n",
    "y_train = np_utils.to_categorical(y_train, num_classes)\n",
    "y_test_keras = np_utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(15):\n",
    "    display(model.layers[i].get_output_shape_at(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for train, test in kfold.split(X, y):\n",
    "\n",
    "model = DCNNv1(num_features, num_classes)\n",
    "\n",
    "model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_test, y_test_keras),\n",
    "    epochs=num_epochs,\n",
    "    batch_size=128,\n",
    "    verbose=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(model.history.history['accuracy'])\n",
    "plt.plot(model.history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(\n",
    "    X_test)\n",
    "predictions = np.argmax(predictions, axis=1)\n",
    "true_labels = np.asarray(y_test)\n",
    "print('CV: ')\n",
    "sns.heatmap(pd.DataFrame(confusion_matrix(true_labels, predictions), range(num_classes), range(num_classes)), annot=True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train = test: make model bigger/dense\n",
    "# increase batch size\n",
    "# train > test: decrease complexity, add dropout, normalization\n",
    "# use stride-2 conv layers instead of maxpooling\n",
    "# increase filter size\n",
    "# possibly add dense layers first\n",
    "# possibly add conv1d\n",
    "# add more gradual dense layers (dropouts in between)\n",
    "# add batch normalisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Sequence = 'CATGCTGACTAGCTG'\n",
    "BinaryEncoding = 110001101101100011010010110110\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame([['Binary Encoding', BinaryEncoding], ['Sequence', Sequence]], columns=['', ''])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maps = {\n",
    "    'A': '00',\n",
    "    'T': '01',\n",
    "    'G': '10',\n",
    "    'C': '11'\n",
    "}\n",
    "\n",
    "print(''.join([maps[i] for i in Sequence]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0467c16d4e73dba61dcc106221b4b7c95372fa61fc6cc648ee99bca30bbaf279"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
