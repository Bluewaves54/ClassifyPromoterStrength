{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim import models\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import keras\n",
    "from keras import layers\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split as tts\n",
    "from keras.utils import np_utils\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_kmers(sequences, kmer=4):\n",
    "    return_seqs = sequences.copy()\n",
    "    # if kmer <= 1:\n",
    "    #     raise ValueError(\"kmer size must be greater than 1\")\n",
    "    for seq_index, seq in sequences.iteritems():\n",
    "        kmer_list = []\n",
    "        enum = seq[:-kmer + 1] if kmer > 1 else seq\n",
    "        for let_index, let in enumerate(enum):\n",
    "            kmer_list.append(seq[let_index:let_index + kmer])\n",
    "        return_seqs[seq_index] = kmer_list\n",
    "    return return_seqs\n",
    "\n",
    "def get_2d_kmer(seqs, mnm, mxm):\n",
    "    return_seqs = []\n",
    "    for _, val in seqs.iteritems():\n",
    "        kmer_seqs = []\n",
    "        for i in range(mnm, mxm+1):\n",
    "            kmers = list(get_kmers(pd.Series([val]), kmer=i))[0]\n",
    "            # kmers += [kmers[-1] for _ in range(i-1)]\n",
    "            kmer_seqs.append(kmers)\n",
    "        return_seqs.append(kmer_seqs)\n",
    "    \n",
    "    return pd.Series(return_seqs)\n",
    "\n",
    "def dup_vecs(dfs):\n",
    "    dup_X_2d = []\n",
    "    for df_ind, df in enumerate(dfs):\n",
    "        num_dupes = 4**(2-df_ind)\n",
    "        print(num_dupes)\n",
    "        new_df = df.values.tolist()\n",
    "        for ind, seq in enumerate(new_df):\n",
    "            new_seq = []\n",
    "            for num in seq:\n",
    "                for i in range(num_dupes):\n",
    "                    new_seq.append(num)\n",
    "            new_df[ind] = new_seq\n",
    "        dup_X_2d.append(pd.DataFrame(new_df))\n",
    "\n",
    "    return dup_X_2d\n",
    "\n",
    "def vectorize_1d(X, kmer, model):\n",
    "    X = get_kmers(kmer)\n",
    "    df_list = []\n",
    "    for _, seq in X.iteritems():\n",
    "        seq_matrix = [model.wv[val] for val in seq]\n",
    "        df_list.append(seq_matrix)\n",
    "    df_list = np.array(df_list)\n",
    "    df_list = df_list.reshape(*df_list.shape, 1).astype('float32')\n",
    "    return df_list\n",
    "\n",
    "\n",
    "def vectorize_2d(X, mnm, mxm, model):\n",
    "\n",
    "    X = get_2d_kmer(X, mnm, mxm)\n",
    "\n",
    "    for _, seq in X.iteritems():\n",
    "        for mer in seq[:-1]:\n",
    "            del mer[-(mxm-len(mer[0])):]\n",
    "\n",
    "    df_list = np.zeros(shape=(6764,mxm-mnm+1,len(X[0][0]),100))\n",
    "    for i, seq in X.iteritems():\n",
    "        seq_matrix = []\n",
    "        for mer in seq:\n",
    "            mer_matrix = []\n",
    "            for val in mer:\n",
    "                # print(val)\n",
    "                mer_matrix.append(model.wv[val])\n",
    "            seq_matrix.append(mer_matrix)\n",
    "            # print(np.array(seq_matrix).shape)\n",
    "        df_list[i] = seq_matrix\n",
    "    df_list = df_list.reshape(*df_list.shape, 1).astype('float32')\n",
    "    return df_list\n",
    "\n",
    "opt = keras.optimizers.Adam(learning_rate=0.0005)\n",
    "\n",
    "def cnn2d(input_shape, num_classes):\n",
    "    model = keras.Sequential()\n",
    "    model.add(layers.Dropout(0.1, input_shape=input_shape))\n",
    "    model.add(layers.Conv2D(32,77, input_shape=input_shape))\n",
    "    model.add(layers.Activation(activation='softsign'))\n",
    "    model.add(layers.Dropout(0.1))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.MaxPooling2D(2))\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(16))\n",
    "    model.add(layers.Activation(activation='softsign'))\n",
    "    model.add(layers.Dense(num_classes))\n",
    "    model.add(layers.Activation(activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def cnn3d(input_shape, num_classes):\n",
    "    model = keras.Sequential()\n",
    "    model.add(layers.Dropout(0.1, input_shape=input_shape))\n",
    "    model.add(layers.Conv3D(32,(input_shape[0]-1, input_shape[1]-1, input_shape[1]-1), input_shape=input_shape))\n",
    "    model.add(layers.Activation(activation='softsign'))\n",
    "    model.add(layers.Dropout(0.1))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.MaxPooling3D(2))\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(16))\n",
    "    model.add(layers.Activation(activation='softsign'))\n",
    "    model.add(layers.Dense(num_classes))\n",
    "    model.add(layers.Activation(activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../data/pro_nonpro.csv')\n",
    "data = data.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.Seq\n",
    "y = data.Level\n",
    "\n",
    "le = LabelEncoder()\n",
    "y = pd.Series(le.fit_transform(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_2d = get_2d_kmer(X, mnm=1, mxm=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for _, seq in X_2d.iteritems():\n",
    "#     for mer in seq[:-1]:\n",
    "#         del mer[-(10-len(mer[0])):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sents = [i for _, v in X_2d.iteritems() for i in v]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec_model = models.Word2Vec(\n",
    "    sentences=sents,\n",
    "    min_count=1,\n",
    "    window=10,\n",
    "    workers=4\n",
    "    )\n",
    "\n",
    "word2vec_model.save('word2vecmodel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.word2vec.Word2Vec.load('./word2vecmodel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inpt_data = vectorize_2d(X, 1, 10, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inpt_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = 100\n",
    "num_classes = 2\n",
    "num_epochs = 150\n",
    "input_shape = inpt_data.shape[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    plt.imshow(inpt_data[0][i], cmap='gray')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = tts(inpt_data, y, train_size=0.8)\n",
    "y_train = np_utils.to_categorical(y_train, num_classes)\n",
    "y_test_keras = np_utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for train, test in kfold.split(X, y):\n",
    "\n",
    "cnn = cnn3d(input_shape, num_classes)\n",
    "\n",
    "history = cnn.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_test, y_test_keras),\n",
    "    epochs=num_epochs,\n",
    "    batch_size=128,\n",
    "    verbose=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max(history.history['val_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = cnn.predict(\n",
    "    X_test)\n",
    "predictions = np.argmax(predictions, axis=1)\n",
    "true_labels = np.asarray(y_test)\n",
    "print('CV: ')\n",
    "sns.heatmap(pd.DataFrame(confusion_matrix(true_labels, predictions), range(num_classes), range(num_classes)), annot=True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv('../data/pro_nonpro.csv')\n",
    "test = test_data.Seq\n",
    "test_val = test_data.Level\n",
    "inpt = vectorize_2d(test, 4, 6, model)\n",
    "pred = cnn.predict(inpt)\n",
    "preds = [list(i).index(max(i)) for i in pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(preds == test_val).count(True) / 6764"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds==test_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12 (main, Apr  4 2022, 05:22:27) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0467c16d4e73dba61dcc106221b4b7c95372fa61fc6cc648ee99bca30bbaf279"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
